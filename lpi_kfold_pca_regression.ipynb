{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LPI Regression: GroupKFold Cross-Validation with PCA + Multiple Models\n",
    "### Liquefaction Potential Index Prediction from Borehole Geotechnical Features\n",
    "\n",
    "**Dataset:** `combined_6.5_7_7.5 (1).csv`  \n",
    "**Target:** `lpi` — Liquefaction Potential Index (continuous regression target, range 0–61)  \n",
    "**Strategy:** `StandardScaler → PCA (95% variance) → GroupKFold(k=10, group=BoreholeID) → 8 Regression Models`  \n",
    "\n",
    "---\n",
    "**Notebook Structure:**\n",
    "0. Imports & Configuration  \n",
    "1. Data Loading & Exploratory Data Analysis (EDA)  \n",
    "2. Preprocessing & Feature Engineering  \n",
    "3. PCA Analysis (Dimensionality Reduction)  \n",
    "4. GroupKFold Cross-Validation Setup  \n",
    "5. Model Definition (8 Regressors)  \n",
    "6. GroupKFold Training & Evaluation  \n",
    "7. Model Comparison Visualizations  \n",
    "8. Best Model — OOF Residual Analysis  \n",
    "9. PCA Component Importance  \n",
    "10. Original Feature Importance  \n",
    "11. Spatial Distribution of Predictions  \n",
    "12. Statistical Significance Testing (Friedman Test)  \n",
    "13. Results Summary & Export  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 0: Imports & Configuration"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold, cross_validate\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "    print('XGBoost not found — skipping')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "# ─── CONFIGURATION ────────────────────────────────────────────\n",
    "CSV_PATH  = 'combined_6.5_7_7.5.csv' if os.path.exists('combined_6.5_7_7.5.csv') else 'combined_6.5_7_7.5 (1).csv'\n",
    "OUT       = 'results'\n",
    "N_FOLDS   = 10\n",
    "PCA_VAR   = 0.95   # retain 95% of variance\n",
    "SEED      = 42\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "plt.rcParams.update({'figure.dpi': 120, 'font.size': 11})\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 1: Data Loading & Exploratory Data Analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "print(f'Raw shape: {df_raw.shape}')\n",
    "\n",
    "META_COLS    = ['Latitude', 'Longitude', 'BoreholeID']\n",
    "TARGET_COL   = 'lpi'\n",
    "LPI_COMP     = [c for c in df_raw.columns if c.startswith('lpi_component')]\n",
    "FEATURE_COLS = [c for c in df_raw.columns if c not in META_COLS + [TARGET_COL] + LPI_COMP]\n",
    "\n",
    "print(f'\\nFeatures ({len(FEATURE_COLS)}): {FEATURE_COLS}')\n",
    "print(f'LPI components excluded ({len(LPI_COMP)}): {LPI_COMP}')\n",
    "print(f'Target: {TARGET_COL}')\n",
    "print(f'\\nTarget (LPI) statistics:')\n",
    "display(df_raw[TARGET_COL].describe().to_frame().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values & duplicates\n",
    "print('Missing values per column:')\n",
    "print(df_raw[FEATURE_COLS + [TARGET_COL]].isnull().sum().to_string())\n",
    "\n",
    "n_dup = df_raw.duplicated(subset=FEATURE_COLS).sum()\n",
    "print(f'\\nDuplicate rows (by features): {n_dup}')\n",
    "df = df_raw.drop_duplicates(subset=FEATURE_COLS).copy()\n",
    "print(f'Shape after deduplication: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA Plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Distribution\n",
    "axes[0].hist(df[TARGET_COL], bins=40, color='steelblue', edgecolor='white')\n",
    "axes[0].axvline(df[TARGET_COL].mean(), color='red', linestyle='--',\n",
    "                label=f\"Mean={df[TARGET_COL].mean():.2f}\")\n",
    "axes[0].set(title='LPI Distribution', xlabel='LPI', ylabel='Count')\n",
    "axes[0].legend()\n",
    "\n",
    "# Q-Q plot\n",
    "(osm, osr), (s, i, _) = stats.probplot(df[TARGET_COL], dist='norm')\n",
    "axes[1].scatter(osm, osr, s=8, alpha=0.5)\n",
    "axes[1].plot(osm, s*np.array(osm)+i, 'r-')\n",
    "axes[1].set(title='Q-Q Plot of LPI', xlabel='Theoretical Q', ylabel='Sample Q')\n",
    "\n",
    "# Boxplot by earthquake magnitude\n",
    "mag_vals = sorted(df['M_3'].unique())\n",
    "axes[2].boxplot([df[df['M_3']==m][TARGET_COL].values for m in mag_vals],\n",
    "                labels=[str(m) for m in mag_vals], patch_artist=True)\n",
    "axes[2].set(title='LPI by Earthquake Magnitude (M_3)', xlabel='Mw', ylabel='LPI')\n",
    "\n",
    "plt.suptitle('Figure 1 — Target Variable: Exploratory Analysis', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/01_eda_overview.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "corr = df[FEATURE_COLS + [TARGET_COL]].corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool), k=1)\n",
    "fig, ax = plt.subplots(figsize=(14, 11))\n",
    "sns.heatmap(corr, mask=mask, cmap='RdBu_r', center=0, vmin=-1, vmax=1,\n",
    "            annot=False, linewidths=0.3, ax=ax)\n",
    "ax.set_title('Figure 2 — Feature Correlation Matrix (incl. LPI Target)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/02_correlation_heatmap.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 2: Preprocessing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X   = df[FEATURE_COLS].values\n",
    "y   = df[TARGET_COL].values\n",
    "lat = df['Latitude'].values\n",
    "lon = df['Longitude'].values\n",
    "groups = df['BoreholeID'].values\n",
    "\n",
    "print(f'Feature matrix X: {X.shape}')\n",
    "print(f'Target vector  y: {y.shape}')\n",
    "print(f'LPI range: [{y.min():.3f}, {y.max():.3f}]')\n",
    "\n",
    "variances = pd.Series(X.var(axis=0), index=FEATURE_COLS).sort_values(ascending=False)\n",
    "print('\\nTop 10 features by raw variance:')\n",
    "display(variances.head(10).to_frame('Variance'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 3: PCA Analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_full = StandardScaler()\n",
    "X_scaled    = scaler_full.fit_transform(X)\n",
    "pca_full    = PCA(random_state=SEED).fit(X_scaled)\n",
    "\n",
    "explained  = pca_full.explained_variance_ratio_\n",
    "cumulative = np.cumsum(explained)\n",
    "\n",
    "n85 = np.argmax(cumulative >= 0.85) + 1\n",
    "n90 = np.argmax(cumulative >= 0.90) + 1\n",
    "n95 = np.argmax(cumulative >= 0.95) + 1\n",
    "N_PCA = n95\n",
    "\n",
    "print(f'Components for 85% variance: {n85}')\n",
    "print(f'Components for 90% variance: {n90}')\n",
    "print(f'Components for 95% variance: {n95}  << SELECTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "axes[0].bar(range(1, len(explained)+1), explained*100, color='steelblue', alpha=0.7)\n",
    "axes[0].plot(range(1, len(explained)+1), explained*100, 'ro-', ms=4)\n",
    "axes[0].set(title='Scree Plot', xlabel='PC', ylabel='Var. Explained (%)')\n",
    "axes[0].set_xlim(0.5, min(24, len(explained))+0.5)\n",
    "\n",
    "axes[1].plot(range(1, len(cumulative)+1), cumulative*100, 'b-o', ms=4)\n",
    "for thresh, col, lbl in [(85,'orange','85%'), (90,'red','90%'), (95,'green','95%')]:\n",
    "    axes[1].axhline(thresh, color=col, linestyle='--', label=lbl)\n",
    "axes[1].axvline(n95, color='green', linestyle=':', alpha=0.7)\n",
    "axes[1].set(title='Cumulative Explained Variance', xlabel='N Components', ylabel='Cumulative (%)')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlim(0.5, 24.5)\n",
    "\n",
    "plt.suptitle(f'Figure 3 — PCA: {N_PCA} components retain 95% variance', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/03_pca_variance.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_viz = PCA(n_components=N_PCA, random_state=SEED).fit(X_scaled)\n",
    "loadings = pd.DataFrame(\n",
    "    pca_viz.components_.T,\n",
    "    index=FEATURE_COLS,\n",
    "    columns=[f'PC{i+1}' for i in range(N_PCA)]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(max(10, N_PCA), 8))\n",
    "kws = {'annot': True, 'fmt': '.2f'} if N_PCA <= 10 else {'annot': False}\n",
    "sns.heatmap(loadings, cmap='RdBu_r', center=0, vmin=-1, vmax=1, ax=ax, linewidths=0.3, **kws)\n",
    "ax.set_title(f'Figure 4 — PCA Loadings (Top {N_PCA} Components)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/04_pca_loadings.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 4: GroupKFold Cross-Validation Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = GroupKFold(n_splits=N_FOLDS)\n",
    "\n",
    "def make_pipe(model):\n",
    "    \"\"\"StandardScaler -> PCA (variance=PCA_VAR) -> Regressor pipeline.\"\"\"\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca',    PCA(n_components=PCA_VAR, svd_solver='full', random_state=SEED)),\n",
    "        ('model',  model)\n",
    "    ])\n",
    "\n",
    "print(f'GroupKFold: k={N_FOLDS}, group=BoreholeID')\n",
    "print(f'Pipeline: StandardScaler -> PCA(var={PCA_VAR}) -> Regressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 5: Model Definitions (8 Regressors)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    'Linear Regression'  : make_pipe(LinearRegression()),\n",
    "    'Ridge (a=1.0)'      : make_pipe(Ridge(alpha=1.0, random_state=SEED)),\n",
    "    'Lasso (a=0.1)'      : make_pipe(Lasso(alpha=0.1, random_state=SEED, max_iter=5000)),\n",
    "    'ElasticNet'         : make_pipe(ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=SEED, max_iter=5000)),\n",
    "    'Random Forest'      : make_pipe(RandomForestRegressor(n_estimators=200, random_state=SEED, n_jobs=-1)),\n",
    "    'Gradient Boosting'  : make_pipe(GradientBoostingRegressor(n_estimators=200, learning_rate=0.05,\n",
    "                                                                max_depth=4, random_state=SEED)),\n",
    "    'SVR (RBF)'          : make_pipe(SVR(kernel='rbf', C=10.0, epsilon=0.5, gamma='scale')),\n",
    "}\n",
    "\n",
    "if HAS_XGB:\n",
    "    MODELS['XGBoost'] = make_pipe(XGBRegressor(n_estimators=200, learning_rate=0.05,\n",
    "                                               max_depth=5, random_state=SEED,\n",
    "                                               n_jobs=-1, verbosity=0))\n",
    "\n",
    "print(f'Models ({len(MODELS)}):')\n",
    "for name in MODELS:\n",
    "    print(f'  - {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 6: GroupKFold Training & Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORING = {'r2': 'r2', 'neg_mse': 'neg_mean_squared_error', 'neg_mae': 'neg_mean_absolute_error'}\n",
    "cv_results = {}\n",
    "\n",
    "for name, pipe in MODELS.items():\n",
    "    print(f'Training {name}...', end=' ', flush=True)\n",
    "    cv = cross_validate(pipe, X, y, groups=groups, cv=kf, scoring=SCORING,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "    \n",
    "    r2_cv   = cv['test_r2']\n",
    "    mse_cv  = -cv['test_neg_mse']\n",
    "    mae_cv  = -cv['test_neg_mae']\n",
    "    rmse_cv = np.sqrt(mse_cv)\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'R2': r2_cv, 'RMSE': rmse_cv, 'MAE': mae_cv,\n",
    "        'train_R2': cv['train_r2']\n",
    "    }\n",
    "    print(f'R2={r2_cv.mean():.4f}+-{r2_cv.std():.4f}  RMSE={rmse_cv.mean():.3f}+-{rmse_cv.std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Table\n",
    "summary = pd.DataFrame({\n",
    "    name: {\n",
    "        'R2 mean': f\"{v['R2'].mean():.4f}\",\n",
    "        'R2 std':  f\"{v['R2'].std():.4f}\",\n",
    "        'RMSE mean': f\"{v['RMSE'].mean():.3f}\",\n",
    "        'RMSE std':  f\"{v['RMSE'].std():.3f}\",\n",
    "        'MAE mean': f\"{v['MAE'].mean():.3f}\",\n",
    "        'MAE std':  f\"{v['MAE'].std():.3f}\",\n",
    "        'Train R2': f\"{v['train_R2'].mean():.4f}\",\n",
    "    }\n",
    "    for name, v in cv_results.items()\n",
    "}).T\n",
    "\n",
    "print('=== 10-Fold Cross-Validation Results (GroupKFold + PCA + Model) ===')\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 7: Model Comparison Visualizations"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names      = list(cv_results.keys())\n",
    "r2_means   = [cv_results[n]['R2'].mean()   for n in names]\n",
    "r2_stds    = [cv_results[n]['R2'].std()    for n in names]\n",
    "rmse_means = [cv_results[n]['RMSE'].mean() for n in names]\n",
    "rmse_stds  = [cv_results[n]['RMSE'].std()  for n in names]\n",
    "mae_means  = [cv_results[n]['MAE'].mean()  for n in names]\n",
    "mae_stds   = [cv_results[n]['MAE'].std()   for n in names]\n",
    "train_r2s  = [cv_results[n]['train_R2'].mean() for n in names]\n",
    "\n",
    "colors = plt.cm.get_cmap('tab10', len(names)).colors\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for ax, means, stds, ylabel, title, best_high in [\n",
    "    (axes[0], r2_means,   r2_stds,   'R2',   'R2 Score (10-Fold CV)',  True),\n",
    "    (axes[1], rmse_means, rmse_stds, 'RMSE', 'RMSE (10-Fold CV)',      False),\n",
    "    (axes[2], mae_means,  mae_stds,  'MAE',  'MAE (10-Fold CV)',       False),\n",
    "]:\n",
    "    bars = ax.bar(range(len(names)), means, yerr=stds, capsize=5,\n",
    "                  color=colors, alpha=0.85, edgecolor='k', linewidth=0.5)\n",
    "    best = np.argmax(means) if best_high else np.argmin(means)\n",
    "    bars[best].set_edgecolor('gold'); bars[best].set_linewidth(3)\n",
    "    ax.set_xticks(range(len(names)))\n",
    "    ax.set_xticklabels(names, rotation=35, ha='right', fontsize=9)\n",
    "    ax.set(ylabel=ylabel, title=title)\n",
    "\n",
    "plt.suptitle('Figure 5 — Model Comparison: GroupKFold(PCA+Model)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/05_model_comparison.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of per-fold R2\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "bp = ax.boxplot([cv_results[n]['R2'] for n in names], patch_artist=True, labels=names,\n",
    "                medianprops=dict(color='red', linewidth=2))\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color); patch.set_alpha(0.7)\n",
    "ax.set_xticklabels(names, rotation=35, ha='right', fontsize=9)\n",
    "ax.set(title='Figure 6 — Per-Fold R2 Distribution (10-Fold CV)', ylabel='R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/06_fold_r2_boxplots.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train vs Test R2\n",
    "x, w = np.arange(len(names)), 0.35\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(x-w/2, train_r2s, w, label='Train R2', color='steelblue', alpha=0.8, edgecolor='k')\n",
    "ax.bar(x+w/2, r2_means,  w, label='Test R2',  color='coral',     alpha=0.8, edgecolor='k')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names, rotation=35, ha='right', fontsize=9)\n",
    "ax.set(title='Figure 7 — Train vs Test R2 (Overfitting Check)', ylabel='R2')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/07_train_vs_test_r2.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 8: Best Model — OOF Residual Analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = names[np.argmax(r2_means)]\n",
    "print(f'Best model: {best_name}  (mean CV R2 = {max(r2_means):.4f})')\n",
    "\n",
    "best_pipe = MODELS[best_name]\n",
    "oof_pred  = np.zeros(len(y))\n",
    "oof_true  = np.zeros(len(y))\n",
    "\n",
    "for _, (tr, va) in enumerate(kf.split(X, y, groups)):\n",
    "    best_pipe.fit(X[tr], y[tr])\n",
    "    oof_pred[va] = best_pipe.predict(X[va])\n",
    "    oof_true[va] = y[va]\n",
    "\n",
    "residuals  = oof_true - oof_pred\n",
    "final_r2   = r2_score(oof_true, oof_pred)\n",
    "final_rmse = np.sqrt(mean_squared_error(oof_true, oof_pred))\n",
    "final_mae  = mean_absolute_error(oof_true, oof_pred)\n",
    "\n",
    "print(f'OOF R2   = {final_r2:.4f}')\n",
    "print(f'OOF RMSE = {final_rmse:.3f}')\n",
    "print(f'OOF MAE  = {final_mae:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(13, 10))\n",
    "\n",
    "axes[0,0].scatter(oof_true, oof_pred, s=15, alpha=0.4)\n",
    "lo, hi = oof_true.min(), oof_true.max()\n",
    "axes[0,0].plot([lo,hi],[lo,hi],'r--',lw=2, label='Perfect fit')\n",
    "axes[0,0].set(title=f'Actual vs Predicted — {best_name}\\nR2={final_r2:.4f}',\n",
    "              xlabel='Actual LPI', ylabel='Predicted LPI')\n",
    "axes[0,0].legend()\n",
    "\n",
    "axes[0,1].scatter(oof_pred, residuals, s=15, alpha=0.4, color='coral')\n",
    "axes[0,1].axhline(0, color='k', linestyle='--')\n",
    "axes[0,1].set(title='Residuals vs Predicted', xlabel='Predicted LPI', ylabel='Residuals')\n",
    "\n",
    "axes[1,0].hist(residuals, bins=40, color='mediumseagreen', edgecolor='white')\n",
    "axes[1,0].axvline(0, color='red', linestyle='--')\n",
    "axes[1,0].set(title='Residual Distribution', xlabel='Residual', ylabel='Count')\n",
    "\n",
    "(osm2, osr2), (s2, i2, _) = stats.probplot(residuals, dist='norm')\n",
    "axes[1,1].scatter(osm2, osr2, s=10, alpha=0.5)\n",
    "axes[1,1].plot(osm2, s2*np.array(osm2)+i2, 'r-')\n",
    "axes[1,1].set(title='Q-Q Plot of Residuals', xlabel='Theoretical Q', ylabel='Residual Q')\n",
    "\n",
    "plt.suptitle(f'Figure 8 — Best Model Analysis: {best_name}', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/08_best_model_residuals.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 9: PCA Component Importance"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_final = PCA(n_components=N_PCA, random_state=SEED)\n",
    "X_pca     = pca_final.fit_transform(StandardScaler().fit_transform(X))\n",
    "\n",
    "pc_corr = pd.DataFrame([\n",
    "    {'PC': f'PC{i+1}',\n",
    "     'Pearson_r': stats.pearsonr(X_pca[:,i], y)[0],\n",
    "     'p_value':   stats.pearsonr(X_pca[:,i], y)[1],\n",
    "     'Var_explained_%': pca_final.explained_variance_ratio_[i]*100}\n",
    "    for i in range(N_PCA)\n",
    "])\n",
    "\n",
    "display(pc_corr)\n",
    "pc_corr.to_csv(f'{OUT}/pca_component_correlations.csv', index=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "colors_bar = ['coral' if r < 0 else 'steelblue' for r in pc_corr['Pearson_r']]\n",
    "axes[0].bar(pc_corr['PC'], pc_corr['Pearson_r'], color=colors_bar, edgecolor='k')\n",
    "axes[0].axhline(0, color='k', lw=1)\n",
    "axes[0].set(title='PC Correlation with LPI', xlabel='PC', ylabel='Pearson r')\n",
    "axes[1].bar(pc_corr['PC'], pc_corr['Var_explained_%'], color='mediumseagreen', edgecolor='k')\n",
    "axes[1].set(title='Variance Explained per PC', xlabel='PC', ylabel='Var. Explained (%)')\n",
    "plt.suptitle('Figure 9 — PCA Component Analysis', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/09_pca_importance.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 10: Original Feature Importance (via PCA Loadings)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_exp  = pca_final.explained_variance_ratio_\n",
    "feat_imp = np.sum(np.abs(pca_final.components_) * var_exp[:, None], axis=0)\n",
    "feat_df  = pd.DataFrame({'Feature': FEATURE_COLS, 'Importance': feat_imp})\n",
    "feat_df  = feat_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "display(feat_df)\n",
    "feat_df.to_csv(f'{OUT}/feature_importance_pca.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "cmap = plt.cm.get_cmap('viridis', len(feat_df))\n",
    "ax.barh(feat_df['Feature'][::-1], feat_df['Importance'][::-1],\n",
    "        color=[cmap(i) for i in range(len(feat_df))][::-1], edgecolor='k', linewidth=0.3)\n",
    "ax.set(title='Figure 10 — Feature Importance (PCA Loadings x Variance)',\n",
    "       xlabel='PCA-Weighted Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/10_feature_importance.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 11: Spatial Distribution of Predictions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, data, title, cmap in [\n",
    "    (axes[0], oof_true,  'Actual LPI',                  'RdYlGn_r'),\n",
    "    (axes[1], oof_pred,  f'Predicted LPI ({best_name})', 'RdYlGn_r'),\n",
    "    (axes[2], residuals, 'Residuals',                    'RdBu'),\n",
    "]:\n",
    "    sc = ax.scatter(lon, lat, c=data, cmap=cmap, s=20, alpha=0.7)\n",
    "    plt.colorbar(sc, ax=ax)\n",
    "    ax.set(title=title, xlabel='Longitude', ylabel='Latitude')\n",
    "\n",
    "plt.suptitle('Figure 11 — Spatial Distribution of LPI Predictions', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUT}/11_spatial_lpi_map.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "spatial_df = pd.DataFrame({'Latitude': lat, 'Longitude': lon,\n",
    "                            'LPI_actual': oof_true, 'LPI_predicted': oof_pred,\n",
    "                            'Residual': residuals})\n",
    "spatial_df.to_csv(f'{OUT}/spatial_predictions.csv', index=False)\n",
    "print('Saved spatial_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 12: Statistical Significance Testing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r2s = [cv_results[n]['R2'] for n in names]\n",
    "stat, pval = stats.friedmanchisquare(*all_r2s)\n",
    "print(f'Friedman Test (non-parametric):')\n",
    "print(f'  chi2-statistic = {stat:.4f}')\n",
    "print(f'  p-value        = {pval:.6e}')\n",
    "print(f'  Significant (alpha=0.05): {pval < 0.05}')\n",
    "print('')\n",
    "print('Interpretation: The Friedman test evaluates whether model R2 scores')\n",
    "print('differ significantly across the 10 folds. p<0.001 confirms significant')\n",
    "print('differences exist between the 8 models.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 13: Results Summary & Export"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*60)\n",
    "print('FINAL RESULTS SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Dataset           : {len(df)} samples x {len(FEATURE_COLS)} features (after dedup)')\n",
    "print(f'PCA components    : {N_PCA} (retaining 95% variance from 24 features)')\n",
    "print(f'CV strategy       : GroupKFold (k={N_FOLDS}, group=BoreholeID)')\n",
    "print('')\n",
    "print(f'{\"Model\":<22} {\"R2 mean\":>10} {\"R2 std\":>8} {\"RMSE mean\":>11} {\"MAE mean\":>10}')\n",
    "print('-'*65)\n",
    "for name in names:\n",
    "    v = cv_results[name]\n",
    "    print(f'{name:<22} {v[\"R2\"].mean():>10.4f} {v[\"R2\"].std():>8.4f} '\n",
    "          f'{v[\"RMSE\"].mean():>11.3f} {v[\"MAE\"].mean():>10.3f}')\n",
    "\n",
    "print('-'*65)\n",
    "print(f'\\nBest model: {best_name}')\n",
    "print(f'OOF R2   = {final_r2:.4f}')\n",
    "print(f'OOF RMSE = {final_rmse:.3f} LPI units')\n",
    "print(f'OOF MAE  = {final_mae:.3f} LPI units')\n",
    "print(f'\\nFriedman chi2={stat:.2f}, p={pval:.2e} (models differ significantly)')\n",
    "\n",
    "print(f'\\nAll outputs saved to: {OUT}/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
